
▩ 예제2.나이브_베이즈_머신러닝_모델로_데이터_분류하기.py

■ 이론과 기출문제

■ 나이브 베이즈의 기본 개념

1. 베이즈 정리를 기반으로 한 확률적 분류 알고리즘입니다

2. 조건부 확률을 이용하여 주어진 데이터가 어떤 클래스에 속할지 예측합니다

3. "나이브(순진한)"라는 이름이 붙은 이유는 모든 특징들이 서로 독립적이라고 가정하기 때문입니다. 

 예: 독버섯을 분류하기 위한 독립변수인 버섯모양, 버섯색깔등이 서로 독립이라고
     가정함.

■  주요 특징

1. 단순성과 효율성

  * 모든 특징이 동등하게 중요하다고 가정
  * 계산이 단순하고 빠른 학습/예측 가능
  * 적은 양의 학습 데이터로도 작동 가능

2. 데이터 처리 능력

 * 잡음과 누락된 데이터에 대해 강건한 특성
 * 주로 텍스트 분류와 같은 범주형 데이터에 적합
 * 수치형 데이터에는 상대적으로 덜 효과적

그림: https://cafe.daum.net/oracleoracle/Sq8G/52

1.사전확률(Prior): 사건 발생 이전의 기본 확률
2.사후확률(Posterior): 새로운 증거를 반영한 갱신된 확률
3.조건부 확률: 특정 사건이 발생했을 때 다른 사건이 발생할 확률

■  나이브 베이즈 확률의 주요 문제점과 해결방안

1. 영확률 문제 (https://cafe.daum.net/oracleoracle/Sotv/553)

  * 학습 데이터에 없는 특징값이 등장할 경우 확률이 0이 되는 문제

  * 라플라스 스무딩을 통해 0이 아닌 작은 값으로 보정하여 해결

2. 독립성 가정의 한계

 * 실제로는 특징들 간 상관관계가 있을 수 있음
 * 단순한 가정에도 불구하고 많은 실제 응용에서 좋은 성능을 보임

■ 활용 분야

1. 텍스트 분류 (스팸 메일 필터링)
2. 감성 분석
3. 문서 분류
4. 의사결정 지원 시스템


문제1. 나이브 베이즈 분류기의 특징으로 옳지 않은 것은? (2016년 제17회 ADsP)

1. 모든 특징이 동등하게 중요하고 독립이라고 가정한다
2. 수치형 특징이 많은 데이터셋에 이상적이다
3. 잡음과 누락 데이터를 잘 처리한다
4. 데이터의 크기에 상관없이 잘 동작한다

정답: 

해설: 나이브 베이즈는 수치형 특징이 많은 데이터셋에는 이상적이지 않습니다. 주로 텍스트 분류와 같은 범주형 데이터에 더 적합합니다.

문제2. 나이브 베이즈에서 발생할 수 있는 문제점과 그 해결방안으로 가장 적절한 것은? (2018년 제28회 ADsP)

1. 과적합 문제 - 데이터 증강을 통해 해결
2. 확률값이 0이 되는 문제 - 라플라스 스무딩으로 해결
3. 학습 속도 저하 - 배치 크기 조정으로 해결
4. 특징 선택의 어려움 - 교차 검증으로 해결

정답: 

해설: 나이브 베이즈에서는 특정 클래스에서 특징값이 나타나지 않을 경우 확률이 0이 되는 문제가 발생할 수 있습니다. 이를 해결하기 위해 라플라스 스무딩을 사용하여 0이 아닌 최소값으로 보정합니다.

문제3. 다음 중 베이즈 정리(Bayes' Theorem)에서 P(B|A)의 의미로 가장 적절한 것은? (2019년 제1회 빅데이터분석기사)

1.사건 A가 발생했을 때 사건 B가 발생할 확률
2.사건 B가 발생했을 때 사건 A가 발생할 확률
3.사건 A와 B가 동시에 발생할 확률
4.사건 B가 발생하기 전 사건 A가 발생할 확률

정답:  

해설: P(B|A)는 조건부 확률로, 사건 A가 발생했을 때 사건 B가 발생할 확률을 의미합니다.



문제4. 베이즈 정리와 관련된 설명 중 옳지 않은 것은? (2017년 제21회 ADsP)

1. P(A|B)는 사후확률(Posterior)로 사건 B 발생 후 갱신된 사건 A의 확률이다
2. P(A)는 사전확률(Prior)로 사건 B 발생 이전의 사건 A의 확률이다
3. 독립 사건의 경우 P(A∩B) = P(A) × P(B)가 성립한다
4. 배반사건의 경우 P(A∩B)는 무한대 값을 가진다

정답: 

해설: 배반사건의 경우 P(A∩B)는 0(공집합)이 됩니다. 두 사건이 동시에 일어날 수 없기 때문입니다.

■  실습1 

# ☆ 첫번째 실습 (간단한 데이터 분류)

#1. 데이터 생성
from sklearn.datasets  import  make_blobs
x, y = make_blobs(centers=2, random_state=8) 
# centers=2 로 하면 클래스가 2개가 생성
# random_state=8 는 R 에서 set.seed(8) 과 똑같습니다. 

#2. 데이터 시각화
import  mglearn  
import  matplotlib.pyplot as plt
type(x) # numpy 배열( 행렬 계산을 빠르게 하기 위한 모듈) 
mglearn.discrete_scatter( x[ :, 0], x[ :, 1], y )

#3. 나이브 베이즈 모델 생성 


#4. 모델 훈련 


#5. 분류 시각화


#6. 모델 평가 


■  실습2.  식용버섯과 독버섯 분류하는 나이브 베이즈 모델 생성하기 

데이터셋 : mushrooms.csv  

#1. 데이터 로드
#2. 데이터 확인
#3. 결측치 확인
#4. 종속변수와 독립변수를 분리 
#5. 범주형 데이터를 숫자형으로 변환
#6. 훈련과 테스트 데이터를 분리
#7. 모델 생성
#8. 모델 훈련 
#9. 모델 예측
#10. 모델 평가
#11. 모델 개선 

# 구현:



문제1.  아이리스 꽃 품종을 분류하는 나이브 베이즈 모델을 생성하시오 !

         훈련과 테스트를 9대1로 나눔
         클래스가 3개이므로 fn 값은 확인안하셔도 됩니다.
         정확도가 가장 높은 라플라스 값이 뭔지 알아내면 됩니다.

#1. 데이터 로드
import pandas as pd
iris = pd.read_csv("c:\\data\\iris2.csv")

#2. 데이터 확인
#3. 결측치 확인
#4. 종속변수와 독립변수 분리
#5. 데이터 정규화
#6. 훈련과 테스트 분리 
#7. 모델 생성
#8. 모델 훈련
#9. 모델 예측
#10. 모델 평가
#11. 모델 개선

