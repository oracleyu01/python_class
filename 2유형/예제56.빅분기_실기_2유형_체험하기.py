# â–£ ì˜ˆì œ56.ë¹…ë¶„ê¸°_ì‹¤ê¸°_2ìœ í˜•_ì²´í—˜í•˜ê¸°.py

ì‹œí—˜í™˜ê²½: https://dataq.goorm.io/exam/3/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%B2%B4%ED%97%98/quiz/4%3Fembed

# â–  ì‹œí—˜í™˜ê²½ ë§Œë“¤ê¸°1. sklearn ì—ì„œ ìœ ë°©ì•” í™˜ì ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

import pandas as pd
from sklearn.datasets import load_breast_cancer
brst = load_breast_cancer()
x, y = brst.data, brst.target

col = brst.feature_names                 # ì»¬ëŸ¼ëª… ë¶ˆëŸ¬ì˜¤ê¸°
X = pd.DataFrame(x , columns=col)        # í•™ìŠµ ë°ì´í„°
y = pd.DataFrame(y, columns=['cancer'])  # ì •ë‹µ ë°ì´í„°

# cust_id ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
X.insert(0, 'cust_id', range(1, 1 + len(X)))  # X.insert(ì»¬ëŸ¼ìë¦¬ë²ˆí˜¸, ì»¬ëŸ¼ëª…, ë°ì´í„° )
X


# â–  ì‹œí—˜í™˜ê²½ ë§Œë“¤ê¸°2. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

# í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test  = train_test_split(X, y,test_size=0.2, random_state=1)

# ë§Œë“  ë°ì´í„°ë¥¼ ì‹œí—˜í™˜ê²½ì— ì €ì¥í•©ë‹ˆë‹¤.
x_train.to_csv("X_train.csv", index=False)
y_train.to_csv("y_train.csv", index=False)
x_test.to_csv("X_test.csv", index=False)


# â–  ì‹œí—˜ë¬¸ì œ í’€ê¸° ì‹œì‘

# 1. ê¸°ê³„ í•™ìŠµ ì‹œí‚¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import pandas as pd
X_test = pd.read_csv("X_test.csv")
X_train = pd.read_csv("X_train.csv")
y_train = pd.read_csv("y_train.csv")

# 2. ë°ì´í„°ë¥¼ ì •ê·œí™” í•©ë‹ˆë‹¤.

# í›ˆë ¨ ë°ì´í„° ì •ê·œí™”
from  sklearn.preprocessing  import MinMaxScaler

scaler=MinMaxScaler()

scaler.fit(x_train)
x_train2 = scaler.transform(x_train)

# í…ŒìŠ¤íŠ¸ë°ì´í„° ì •ê·œí™”
from  sklearn.preprocessing  import MinMaxScaler

scaler=MinMaxScaler()

scaler.fit(x_test)
x_test2 = scaler.transform(x_test)

# 3. ì •ë‹µ ë°ì´í„° ë§Œë“¤ê¸°

y = y_train['cancer']
y

# 4. ëª¨ë¸ ìƒì„±

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()


# 5. ëª¨ë¸í›ˆë ¨
model.fit(x_train2, y)

# 6. ëª¨ë¸ì˜ˆì¸¡
pred = model.predict(x_test2)
pred

# 7. ì •ë‹µì œì¶œ

# ë‹µì•ˆ ì œì¶œ ì°¸ê³ 
# ì•„ë˜ ì½”ë“œ ì˜ˆì¸¡ë³€ìˆ˜ì™€ ìˆ˜í—˜ë²ˆí˜¸ë¥¼ ê°œì¸ë³„ë¡œ ë³€ê²½í•˜ì—¬ í™œìš©
# pd.DataFrame({'cust_id': X_test.cust_id, 'label': pred }).to_csv('003000000.csv', index=False)
pd.DataFrame({'cust_id': X_test.cust_id, 'label': pred }).to_csv('003000000.csv', index=False)

# 8. ëª¨ë¸í‰ê°€
from sklearn.metrics import roc_auc_score

y_hat = model.predict(x_train2)
print( roc_auc_score(y, y_hat))




# ğŸ˜Š ë¬¸ì œ:

ìë™ì°¨ì˜ ì—°ë¹„ ì˜ˆì¸¡ì„ ìœ„í•´ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ êµ¬ì¶•í•˜ì„¸ìš”.
ë°ì´í„°ì…‹ì€ ê° ìë™ì°¨ì˜ íŠ¹ì„±(ì˜ˆ: ì°¨ëŸ‰_ì—°ì‹, ì£¼í–‰ê±°ë¦¬, ì—°ë£Œë¹„, ì—”ì§„ í¬ê¸°, ì°¨ëŸ‰ ë¬´ê²Œ)ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì—°ë¹„ëŠ” ì„¸ ê°€ì§€ ë²”ì£¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.

1. ê³ ì—°ë¹„: ë§¤ìš° ê²½ì œì ì¸ ì°¨ëŸ‰
2. ì¤‘ê°„ì—°ë¹„: ì ë‹¹í•œ ê²½ì œì„±ì„ ê°€ì§„ ì°¨ëŸ‰
3. ì €ì—°ë¹„: ê²½ì œì ì´ì§€ ì•Šì€ ì°¨ëŸ‰

ëª¨ë¸ì˜ í‰ê°€ëŠ” f1 score ë¡œ í‰ê°€ë©ë‹ˆë‹¤.

# ì£¼ì–´ì§„ ë°ì´í„° :

í›ˆë ¨ ë°ì´í„°: train.csv
í…ŒìŠ¤íŠ¸ ë°ì´í„° : test.csv

# ì œì¶œ í˜•ì‹

pred
ì¤‘ê°„ì—°ë¹„
ì¤‘ê°„ì—°ë¹„
ì¤‘ê°„ì—°ë¹„
ì¤‘ê°„ì—°ë¹„
ì €ì—°ë¹„
ì¤‘ê°„ì—°ë¹„
ì¤‘ê°„ì—°ë¹„
ì €ì—°ë¹„
ì €ì—°ë¹„
ì¤‘ê°„ì—°ë¹„

ê°€ìƒì˜ ë°ì´í„° ë§Œë“¤ê¸°:

import pandas as pd
import numpy as np

# 1. ê°€ìƒ ë°ì´í„° ìƒì„±
np.random.seed(42)
n_samples = 1000

# ë³€ìˆ˜ ìƒì„±
ì°¨ëŸ‰_ì—°ì‹ = np.random.randint(2000, 2021, n_samples)
ì£¼í–‰ê±°ë¦¬ = np.random.randint(5000, 100000, n_samples)  # ìƒí•œì„  ì¤„ì„
ì—°ë£Œë¹„ = np.random.randint(50, 100, n_samples)  # ê²½ì œì„± ë°˜ì˜
ì—”ì§„_í¬ê¸° = np.random.randint(1000, 2000, n_samples)  # ì‘ì€ ì—”ì§„ í¬ê¸°
ì°¨ëŸ‰_ë¬´ê²Œ = np.random.randint(800, 1500, n_samples)  # ê°€ë²¼ìš´ ì°¨ëŸ‰

# ì—°ë¹„ë¥¼ ë‹¤ì¤‘ ë¶„ë¥˜ë¡œ ìˆ˜ì • ('ê³ ì—°ë¹„', 'ì¤‘ê°„ì—°ë¹„', 'ì €ì—°ë¹„')
ì—°ë¹„ = np.where(
    (ì—°ë£Œë¹„ < 70) & (ì£¼í–‰ê±°ë¦¬ < 50000) & (ì—”ì§„_í¬ê¸° < 1500) & (ì°¨ëŸ‰_ë¬´ê²Œ < 1200),
    'ê³ ì—°ë¹„',
    np.where((ì—°ë£Œë¹„ < 90) & (ì£¼í–‰ê±°ë¦¬ < 70000), 'ì¤‘ê°„ì—°ë¹„', 'ì €ì—°ë¹„')
)

# ë°ì´í„° í”„ë ˆì„ ìƒì„±
data = {
    'ì°¨ëŸ‰_ì—°ì‹': ì°¨ëŸ‰_ì—°ì‹,
    'ì£¼í–‰ê±°ë¦¬': ì£¼í–‰ê±°ë¦¬,
    'ì—°ë£Œë¹„': ì—°ë£Œë¹„,
    'ì—”ì§„ í¬ê¸°': ì—”ì§„_í¬ê¸°,
    'ì°¨ëŸ‰ ë¬´ê²Œ': ì°¨ëŸ‰_ë¬´ê²Œ,
    'ì—°ë¹„': ì—°ë¹„
}

df = pd.DataFrame(data)

# 2. í•™ìŠµ ë°ì´í„° CSV íŒŒì¼ë¡œ ì €ì¥ (train.csv)
df.to_csv('train.csv', index=False)

# 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (ì—°ë¹„ ì œì™¸)
n_samples = 500
test_data = {
    'ì°¨ëŸ‰_ì—°ì‹': np.random.randint(2000, 2021, n_samples),
    'ì£¼í–‰ê±°ë¦¬': np.random.randint(5000, 100000, n_samples),
    'ì—°ë£Œë¹„': np.random.randint(50, 100, n_samples),
    'ì—”ì§„ í¬ê¸°': np.random.randint(1000, 2000, n_samples),
    'ì°¨ëŸ‰ ë¬´ê²Œ': np.random.randint(800, 1500, n_samples)
}

df_test = pd.DataFrame(test_data)

# 4. í…ŒìŠ¤íŠ¸ ë°ì´í„° CSV íŒŒì¼ë¡œ ì €ì¥ (test.csv)
df_test.to_csv('test.csv', index=False)


ë‹µ:


