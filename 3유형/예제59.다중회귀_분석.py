■■ 예제59.다중회귀_분석.py

"""
📌 다중 회귀분석(Multiple Linear Regression) 정리
"""

=============================================================================
📌 1. 다중 회귀분석이란?
=============================================================================

🎨그림: https://github.com/oracleyu01/python_class/blob/main/3유형/다중선형회귀.png

- 하나의 종속변수(Y)와 두 개 이상의 독립변수(X₁, X₂, ..., Xₙ) 간의 관계를 분석하는 회귀 모델.
- 단순 선형 회귀보다 복잡한 관계를 설명하고, 더 높은 예측력을 제공함.
- 회귀식:
  
  Y = a₁X₁ + a₂X₂ + ... + aₙXₙ + b  

- a₁, a₂, ..., aₙ: 독립변수들의 회귀계수 (각 변수의 영향력)
- b: 절편 (Intercept)
- 다중 회귀분석에서는 각 독립변수가 종속변수에 미치는 영향을 고려하여 최적의 회귀식을 도출함.

=============================================================================
📌 2. 다중 회귀분석의 가정 (Assumptions)
=============================================================================

✅ 선형성 (Linearity)  
  - 독립변수(X)와 종속변수(Y) 간에 선형 관계가 존재해야 함.  

✅ 독립성 (Independence)  
  - 각 데이터 포인트의 잔차(오차)들은 서로 독립적이어야 함.  

✅ 등분산성 (Homoscedasticity)  
  - 오차(잔차)의 분산이 일정해야 함.  

✅ 정규성 (Normality)  
  - 잔차가 정규분포를 따라야 함.  

✅ 다중공선성 없음 (No Multicollinearity)  
  - 독립변수들 간의 상관관계가 너무 높으면 모델이 불안정해짐.  
  - 분산팽창계수(VIF, Variance Inflation Factor)를 활용하여 다중공선성을 확인함.  

=============================================================================
📌 3. 다중 회귀분석 모델의 평가 방법
=============================================================================
    
✅ 결정계수(R²)  
  - 모델이 종속변수를 얼마나 잘 설명하는지 나타내는 지표.  
  - 값이 1에 가까울수록 좋은 모델.  

✅ 수정된 결정계수(Adjusted R²)  
  - 변수의 개수에 따른 R² 조정값.  
  - 독립변수 개수가 많아지면 일반 R²는 증가하지만, 모델의 성능이 반드시 좋아지는 것은 아님.  
  - 수정된 R²는 불필요한 변수가 추가되면 패널티를 부과함.  

✅ p-value  
  - 회귀계수가 유의미한지 확인하는 값.  
  - 일반적으로 p-value < 0.05이면 해당 독립변수가 유의미함.  

✅ F-검정 (F-test)  
  - 전체 회귀모델이 유의미한지 검정하는 방법.  

✅ 다중공선성 검토 (Multicollinearity Check)  
  - 독립변수 간 상관관계를 확인하여 다중공선성이 있는 경우 해결 필요.  
  - 분산팽창계수(VIF)를 사용하여 VIF 값이 10 이상이면 다중공선성이 높다고 판단.  

=============================================================================
📌 4. 다중 회귀분석 모델의 해석
=============================================================================
- 회귀계수(a₁, a₂, ..., aₙ)의 부호와 크기를 분석하여 독립변수가 종속변수에 미치는 영향을 평가함.  
- p-value가 낮은 변수는 종속변수에 유의미한 영향을 미치는 변수임.  
- 모델의 성능을 높이기 위해 변수 선택 방법(전진 선택법, 후진 제거법, 단계적 선택법)을 활용할 수 있음.  

"""
📌 변수 선택 방법 (Variable Selection Methods) 정리
"""

=============================================================================
📌 1. 변수 선택이란?
=============================================================================
- 다중 회귀분석에서는 독립변수의 개수가 많을수록 모델이 복잡해지고, 다중공선성 문제가 발생할 가능성이 있음.  
- 불필요한 변수를 제거하여 **모델의 성능을 최적화하고 해석력을 높이는 과정**이 필요함.  
- 대표적인 변수 선택 방법: **전진 선택법(Forward Selection), 후진 제거법(Backward Elimination), 단계적 선택법(Stepwise Selection)**

=============================================================================
📌 2. 전진 선택법 (Forward Selection)
=============================================================================
✅ 개념  
  - 변수를 하나씩 추가하면서 모델을 개선하는 방식.  
  - 초기에는 상수항(Intercept)만 포함하고, 가장 유의미한 변수를 하나씩 추가함.  
  - 추가된 변수의 유의성(p-value 기준)을 검토하면서 변수 선택을 진행.  

✅ 과정  
  1. 먼저, 회귀모델에 아무 변수도 포함하지 않은 상태(Intercept만 포함)에서 시작.  
  2. 모든 독립변수 중에서 **가장 p-value가 작은 변수**를 추가.  
  3. 새롭게 추가된 모델에서 다시 p-value를 계산하고, 특정 임계값(보통 0.05)보다 작으면 유지.  
  4. 위 과정을 반복하며 추가할 변수가 없을 때까지 진행.  


=============================================================================
📌 3. 후진 제거법 (Backward Elimination)
=============================================================================
✅ 개념  
  - 모든 변수를 포함한 상태에서 시작한 후, **유의하지 않은 변수를 하나씩 제거하는 방식**.  
  - p-value가 가장 높은 변수부터 제거하면서 최적의 모델을 찾음.  

✅ 과정  
  1. 모든 독립변수를 포함한 회귀모델을 생성.  
  2. 가장 p-value가 큰 변수를 제거 (보통 p-value > 0.05인 경우).  
  3. 변수를 제거한 새로운 모델에서 다시 p-value를 계산하고, 가장 높은 변수를 제거.  
  4. 위 과정을 반복하며 모든 변수가 유의미할 때까지 진행.  


=============================================================================
📌 4. 단계적 선택법 (Stepwise Selection)
=============================================================================
✅ 개념  
  - 전진 선택법과 후진 제거법을 결합한 방식.  
  - 변수를 추가하면서 동시에 유의하지 않은 변수를 제거하는 절차를 반복.  

✅ 과정  
  1. 전진 선택법과 동일하게 **p-value가 가장 작은 변수**부터 추가.  
  2. 변수를 추가할 때마다 기존 변수들의 p-value를 다시 계산.  
  3. 새롭게 추가된 변수가 다른 변수의 유의성에 영향을 미칠 경우, **p-value가 커진 변수는 제거**.  
  4. 위 과정을 반복하여 더 이상 추가하거나 제거할 변수가 없을 때까지 진행.  



문제1. 다중공선성과 VIF에 대한 설명으로 옳은 것은?
     (2024년 제8회 빅데이터분석기사 필기)

  1. VIF가 1보다 작으면 다중공선성이 있다
  2. 다중회귀에서 독립변수 간 선형관계가 있으면 다중공선성이 있다
  3. 다중공선성이 있어도 예측에는 문제가 없다
  4. VIF가 5 이하면 다중공선성이 없다고 본다

정답: 


문제2. 다중회귀분석에서 결정계수(R²)에 대한 설명으로 틀린 것은?
      (2023년 제6회 빅데이터분석기사 필기)

  1. 결정계수는 1에 가까울수록 좋으나, 무조건 크다고 좋은 것은 아니다
  2. 결정계수는 전체 변동 중 회귀식이 설명 불가능한 변동의 비율이다
  3. 결정계수는 SSR/SST로 구할 수 있다
  4. 다중회귀분석에서 모델 선택 시 수정 결정계수도 함께 고려할 필요가 있다

정답: 


문제3. 다중회귀분석에서 독립변수 간 선형관계가 존재하여 회귀식이 오류를 범할 수 있는 것은?
      (2022년 제4회 빅데이터분석기사 필기)

 1. 이상치
 2. 등분산성
 3. 다중공선성
 4. 독립성

정답: 


■ 실습1.

# ➡️ 미국민 의료비를 예측하는 다중 회귀 모델 생성하기
# 
# #1. 데이터를 불러옵니다.
# #2. 데이터를 살펴봅니다.
# #3. 다중회귀 분석 모델을 생성합니다.
# #4. 회귀분석 결과를 해석합니다.
# #5. 회귀분석 모델의 성능을 높입니다. 


# #1. 데이터를 불러옵니다.
ins = pd.read_csv("insurance.csv")








■ 문제1. 우주 왕복선 데이터를 다중회귀분석하여 o형링 파손에 
         가장 큰 영향을 주는 독립변수가 무엇인지 출력하시오 



